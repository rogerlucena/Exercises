
--- Some of my notes, useful links and observations ---


-- Tree traversals (Inorder, Preorder and Posorder)
http://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/

E.g.: Inorder:
1) left child
2) this.data
3) right child
(The other traversals just change the position of this.data)

Obs: Preorder to copy the tree (polish_notation too), Posorder to delete, Inorder to get int numbers in ascending order from a BST

- Construct Tree from given Inorder and Preorder traversals:
http://www.geeksforgeeks.org/construct-tree-from-given-inorder-and-preorder-traversal/

- Construct a Binary Search Tree from given postorder
http://www.geeksforgeeks.org/construct-a-binary-search-tree-from-given-postorder/


-- STL Containers Complexities:
https://www.cs.northwestern.edu/~riesbeck/programming/c++/stl-summary.html


-- Sorting:

- Stable means that i < j, A[i] == A[j], than pi(i) < pi(j), where "pi" is the map for the new positions (after sorting).
- Merge sort is stable, quick and heap are not:
https://www.geeksforgeeks.org/stability-in-sorting-algorithms/

- Quick Sort (chache friendly, not stable, in place, worst case is O(nÂ²), but avoided if we choose a good pivot (near the median) - random):
https://www.geeksforgeeks.org/quick-sort/

- Merge Sort (stable, additional O(n) in space but better for big data in different databases. For linked lists, where insertion is O(1), no need of additional space):
https://www.geeksforgeeks.org/merge-sort/

- Counting Sort (auxiliar array - 0 to 100 ages, O(n) time) and Radix Sort (O(kn) where k = log(max_el))
They are better exaplined on the Cracking the Coding Interview


--
